{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.3 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "5af03e6f6884cdcbf495aa98cbd8d63d5d0ed05506dbd026ba0a4981213ae30b"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Parsing page 1 of pdf file...\n",
      "Parsing page 2 of pdf file...\n",
      "Parsing page 3 of pdf file...\n",
      "Parsing page 4 of pdf file...\n",
      "Parsing page 5 of pdf file...\n",
      "Parsing page 6 of pdf file...\n",
      "Parsing page 7 of pdf file...\n",
      "Parsing page 8 of pdf file...\n",
      "Parsing page 9 of pdf file...\n",
      "Parsing page 10 of pdf file...\n",
      "Parsing page 11 of pdf file...\n",
      "Parsing page 12 of pdf file...\n",
      "Parsing page 13 of pdf file...\n",
      "Parsing page 14 of pdf file...\n",
      "Parsing page 15 of pdf file...\n",
      "Parsing page 16 of pdf file...\n",
      "Parsing page 17 of pdf file...\n",
      "Parsing page 18 of pdf file...\n",
      "Parsing page 19 of pdf file...\n",
      "Parsing page 20 of pdf file...\n",
      "Parsing page 21 of pdf file...\n",
      "Parsing page 22 of pdf file...\n",
      "Parsing page 23 of pdf file...\n",
      "Parsing page 24 of pdf file...\n",
      "Parsing page 25 of pdf file...\n",
      "Parsing page 26 of pdf file...\n",
      "Parsing page 27 of pdf file...\n",
      "Parsing page 28 of pdf file...\n",
      "Parsing page 29 of pdf file...\n",
      "Parsing page 30 of pdf file...\n",
      "Parsing page 31 of pdf file...\n",
      "Parsing page 32 of pdf file...\n",
      "Parsing page 33 of pdf file...\n",
      "Parsing page 34 of pdf file...\n",
      "Parsing page 35 of pdf file...\n",
      "Parsing page 36 of pdf file...\n",
      "Parsing page 37 of pdf file...\n",
      "Parsing page 38 of pdf file...\n",
      "Parsing page 39 of pdf file...\n",
      "Parsing page 40 of pdf file...\n",
      "Parsing page 41 of pdf file...\n",
      "Parsing page 42 of pdf file...\n",
      "Parsing page 43 of pdf file...\n",
      "Parsing page 44 of pdf file...\n",
      "Parsing page 45 of pdf file...\n",
      "Parsing page 46 of pdf file...\n",
      "Parsing page 47 of pdf file...\n",
      "Parsing page 48 of pdf file...\n",
      "Parsing page 49 of pdf file...\n",
      "Parsing page 50 of pdf file...\n",
      "Parsing page 51 of pdf file...\n",
      "Parsing page 52 of pdf file...\n",
      "Parsing page 53 of pdf file...\n",
      "Parsing page 54 of pdf file...\n",
      "Parsing page 55 of pdf file...\n",
      "Parsing page 56 of pdf file...\n",
      "Parsing page 57 of pdf file...\n",
      "Parsing page 58 of pdf file...\n",
      "Parsing page 59 of pdf file...\n",
      "Parsing page 60 of pdf file...\n",
      "Parsing page 61 of pdf file...\n",
      "Parsing page 62 of pdf file...\n",
      "Parsing page 63 of pdf file...\n",
      "Parsing page 64 of pdf file...\n",
      "Parsing page 65 of pdf file...\n",
      "Parsing page 66 of pdf file...\n",
      "Parsing page 67 of pdf file...\n",
      "Parsing page 68 of pdf file...\n",
      "Parsing page 69 of pdf file...\n",
      "Parsing page 70 of pdf file...\n",
      "Parsing page 71 of pdf file...\n",
      "Parsing page 72 of pdf file...\n",
      "Parsing page 73 of pdf file...\n",
      "Parsing page 74 of pdf file...\n",
      "Parsing page 75 of pdf file...\n",
      "Parsing page 76 of pdf file...\n",
      "Parsing page 77 of pdf file...\n",
      "Parsing page 78 of pdf file...\n",
      "Parsing page 79 of pdf file...\n",
      "Parsing page 80 of pdf file...\n",
      "Parsing page 81 of pdf file...\n",
      "Parsing page 82 of pdf file...\n",
      "Parsing page 83 of pdf file...\n",
      "Parsing page 84 of pdf file...\n",
      "Parsing page 85 of pdf file...\n",
      "Parsing page 86 of pdf file...\n",
      "Parsing page 87 of pdf file...\n",
      "Parsing page 88 of pdf file...\n",
      "Parsing page 89 of pdf file...\n",
      "Parsing page 90 of pdf file...\n",
      "Parsing page 91 of pdf file...\n",
      "Parsing page 92 of pdf file...\n",
      "Parsing page 93 of pdf file...\n",
      "Parsing page 94 of pdf file...\n",
      "Parsing page 95 of pdf file...\n",
      "Parsing page 96 of pdf file...\n",
      "Parsing page 97 of pdf file...\n",
      "Parsing page 98 of pdf file...\n",
      "Parsing page 99 of pdf file...\n",
      "Parsing page 100 of pdf file...\n",
      "Parsing page 101 of pdf file...\n",
      "Parsing page 102 of pdf file...\n",
      "Parsing page 103 of pdf file...\n",
      "Parsing page 104 of pdf file...\n",
      "Parsing page 105 of pdf file...\n",
      "Parsing page 106 of pdf file...\n",
      "Parsing page 107 of pdf file...\n",
      "Parsing page 108 of pdf file...\n",
      "Parsing page 109 of pdf file...\n",
      "Parsing page 110 of pdf file...\n",
      "Parsing page 111 of pdf file...\n",
      "Parsing page 112 of pdf file...\n",
      "Parsing page 113 of pdf file...\n",
      "Parsing page 114 of pdf file...\n",
      "Parsing page 115 of pdf file...\n",
      "Parsing page 116 of pdf file...\n",
      "Parsing page 117 of pdf file...\n",
      "Parsing page 118 of pdf file...\n",
      "Parsing page 119 of pdf file...\n",
      "Parsing page 120 of pdf file...\n",
      "Parsing page 121 of pdf file...\n",
      "Parsing page 122 of pdf file...\n",
      "Parsing page 123 of pdf file...\n",
      "Parsing page 124 of pdf file...\n",
      "Parsing page 125 of pdf file...\n",
      "Parsing page 126 of pdf file...\n",
      "Parsing page 127 of pdf file...\n",
      "Parsing page 128 of pdf file...\n",
      "Parsing page 129 of pdf file...\n",
      "Parsing page 130 of pdf file...\n",
      "Parsing page 131 of pdf file...\n",
      "Parsing page 132 of pdf file...\n",
      "Parsing page 133 of pdf file...\n",
      "Parsing page 134 of pdf file...\n",
      "Parsing page 135 of pdf file...\n",
      "Parsing page 136 of pdf file...\n",
      "Parsing page 137 of pdf file...\n",
      "Parsing page 138 of pdf file...\n",
      "Parsing page 139 of pdf file...\n",
      "Parsing page 140 of pdf file...\n",
      "Parsing page 141 of pdf file...\n",
      "Parsing page 142 of pdf file...\n",
      "Parsing page 143 of pdf file...\n",
      "Parsing page 144 of pdf file...\n",
      "Parsing page 145 of pdf file...\n",
      "Parsing page 146 of pdf file...\n",
      "Parsing page 147 of pdf file...\n",
      "Parsing page 148 of pdf file...\n",
      "Parsing page 149 of pdf file...\n",
      "Parsing page 150 of pdf file...\n",
      "Parsing page 151 of pdf file...\n",
      "Parsing page 152 of pdf file...\n",
      "Parsing page 153 of pdf file...\n",
      "Parsing page 154 of pdf file...\n",
      "Parsing page 155 of pdf file...\n",
      "Parsing page 156 of pdf file...\n",
      "Parsing page 157 of pdf file...\n",
      "Parsing page 158 of pdf file...\n",
      "Parsing page 159 of pdf file...\n",
      "Parsing page 160 of pdf file...\n",
      "Parsing page 161 of pdf file...\n",
      "Parsing page 162 of pdf file...\n",
      "Parsing page 163 of pdf file...\n",
      "Parsing page 164 of pdf file...\n",
      "Parsing page 165 of pdf file...\n",
      "Parsing page 166 of pdf file...\n",
      "Parsing page 167 of pdf file...\n",
      "Parsing page 168 of pdf file...\n",
      "Parsing page 169 of pdf file...\n",
      "Parsing page 170 of pdf file...\n",
      "Parsing page 171 of pdf file...\n",
      "Parsing page 172 of pdf file...\n",
      "Parsing page 173 of pdf file...\n",
      "Parsing page 174 of pdf file...\n",
      "Parsing page 175 of pdf file...\n",
      "Parsing page 176 of pdf file...\n",
      "Parsing page 177 of pdf file...\n",
      "Parsing page 178 of pdf file...\n",
      "Parsing page 179 of pdf file...\n",
      "Parsing page 180 of pdf file...\n",
      "Parsing page 181 of pdf file...\n",
      "Parsing page 182 of pdf file...\n",
      "Parsing page 183 of pdf file...\n",
      "Parsing page 184 of pdf file...\n",
      "Parsing page 185 of pdf file...\n",
      "Parsing page 186 of pdf file...\n",
      "Parsing page 187 of pdf file...\n",
      "Parsing page 188 of pdf file...\n",
      "Parsing page 189 of pdf file...\n",
      "Parsing page 190 of pdf file...\n",
      "Parsing page 191 of pdf file...\n",
      "Parsing page 192 of pdf file...\n",
      "Parsing page 193 of pdf file...\n",
      "Parsing page 194 of pdf file...\n",
      "Parsing page 195 of pdf file...\n",
      "Parsing page 196 of pdf file...\n",
      "Parsing page 197 of pdf file...\n",
      "Parsing page 198 of pdf file...\n",
      "Parsing page 199 of pdf file...\n",
      "Parsing page 200 of pdf file...\n",
      "Parsing page 201 of pdf file...\n",
      "Parsing page 202 of pdf file...\n",
      "Parsing page 203 of pdf file...\n",
      "Parsing page 204 of pdf file...\n",
      "Parsing page 205 of pdf file...\n",
      "Parsing page 206 of pdf file...\n",
      "Parsing page 207 of pdf file...\n",
      "Parsing page 208 of pdf file...\n",
      "Parsing page 209 of pdf file...\n",
      "Parsing page 210 of pdf file...\n",
      "Parsing page 211 of pdf file...\n",
      "Parsing page 212 of pdf file...\n",
      "Parsing page 213 of pdf file...\n",
      "Parsing page 214 of pdf file...\n",
      "Parsing page 215 of pdf file...\n",
      "Parsing page 216 of pdf file...\n",
      "Parsing page 217 of pdf file...\n",
      "Parsing page 218 of pdf file...\n",
      "Parsing page 219 of pdf file...\n",
      "Parsing page 220 of pdf file...\n",
      "Parsing page 221 of pdf file...\n",
      "Parsing page 222 of pdf file...\n",
      "Parsing page 223 of pdf file...\n",
      "Parsing page 224 of pdf file...\n",
      "Parsing page 225 of pdf file...\n",
      "Parsing page 226 of pdf file...\n",
      "Parsing page 227 of pdf file...\n",
      "Parsing page 228 of pdf file...\n",
      "Parsing page 229 of pdf file...\n",
      "Parsing page 230 of pdf file...\n",
      "Parsing page 231 of pdf file...\n",
      "Parsing page 232 of pdf file...\n",
      "Parsing page 233 of pdf file...\n",
      "Parsing page 234 of pdf file...\n",
      "Parsing page 235 of pdf file...\n",
      "Parsing page 236 of pdf file...\n",
      "Parsing page 237 of pdf file...\n",
      "Parsing page 238 of pdf file...\n",
      "Parsing page 239 of pdf file...\n",
      "Parsing page 240 of pdf file...\n",
      "Parsing page 241 of pdf file...\n",
      "Parsing page 242 of pdf file...\n",
      "Parsing page 243 of pdf file...\n",
      "Parsing page 244 of pdf file...\n",
      "Parsing page 245 of pdf file...\n",
      "Parsing page 246 of pdf file...\n",
      "Parsing page 247 of pdf file...\n",
      "Parsing page 248 of pdf file...\n",
      "Parsing page 249 of pdf file...\n",
      "Parsing page 250 of pdf file...\n",
      "Parsing page 251 of pdf file...\n",
      "Parsing page 252 of pdf file...\n"
     ]
    }
   ],
   "source": [
    "from io import StringIO\n",
    "from bs4 import BeautifulSoup\n",
    "from tika import parser\n",
    "import re\n",
    "\n",
    "file_path = \"../Books Index for Phrases/Derivatives Demystified-A Step-by-Step Guide to Forwards, Futures, Swaps _ Options-sAyYiEd.pdf\"\n",
    "\n",
    "file_data = []\n",
    "_buffer = StringIO()\n",
    "data = parser.from_file(file_path, xmlContent=True)\n",
    "xhtml_data = BeautifulSoup(data['content'])\n",
    "for page, content in enumerate(xhtml_data.find_all('div', attrs={'class': 'page'})):\n",
    "    print('Parsing page {} of pdf file...'.format(page+1))\n",
    "    _buffer = StringIO()\n",
    "    _buffer.write(str(content))\n",
    "    parsed_content = parser.from_buffer(_buffer.getvalue())\n",
    "    _buffer.truncate()\n",
    "    file_data.append({'id': 'page_'+str(page+1), 'content': parsed_content['content']})"
   ]
  },
  {
   "source": [
    "## Glossary"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Glossary ## \n",
    "## Page 213 (232) to Page 225 (244)\n",
    "glossary_pages = xhtml_data.find_all('div', attrs={'class': 'page'})[231: 244]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "glossary_page_1 = glossary_pages[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<div class=\"page\"><p></p>\n",
       "<p>Appendix B 215\n",
       "</p>\n",
       "<p>Call feature A feature that allows the issuer of a bond to redeem the bond before maturity.\n",
       "Call option The right but not the obligation to buy an underlying asset at a fixed strike price.\n",
       "Caplet One component of an interest rate cap.\n",
       "Capped floating rate note (FRN) The rate of interest on the note cannot exceed a given\n",
       "</p>\n",
       "<p>level.\n",
       "Cash-and-carry arbitrage Selling over-priced futures contracts and buying the underlying\n",
       "</p>\n",
       "<p>to achieve a risk-free profit. Or buying under-priced futures and shorting the underlying.\n",
       "Cash-or-nothing option Pays out a fixed amount of cash if it expires in-the-money, otherwise\n",
       "</p>\n",
       "<p>nothing.\n",
       "Cash security An underlying security rather than a derivative.\n",
       "Cash settlement Settling a derivative contract in cash rather than through the physical de-\n",
       "</p>\n",
       "<p>livery of the underlying asset.\n",
       "Cheapest-to-deliver bond (CTD) The bond that is the cheapest to deliver against a short\n",
       "</p>\n",
       "<p>position in a bond futures contract.\n",
       "Chicago Board Options Exchange (CBOE) The major options exchange founded in 1973.\n",
       "Chicago Board of Trade (CBOT) Started as a commodity market in the nineteenth century\n",
       "</p>\n",
       "<p>and has now developed major financial futures and options contracts, e.g. on US Treasury\n",
       "bonds.\n",
       "</p>\n",
       "<p>Chicago Mercantile Exchange (CME) The Chicago futures and options exchange where\n",
       "the key Eurodollar futures contract trades. Also known as the ‘Merc’.\n",
       "</p>\n",
       "<p>Chooser option The holder can decide at a preset time whether it is a call or a put option.\n",
       "Also known as a U-Choose, as-you-like, call-or-put option.\n",
       "</p>\n",
       "<p>Clean price The price of a bond excluding interest accrued since the last coupon date.\n",
       "Clearing house The organization that registers, matches, monitors and guarantees trades\n",
       "</p>\n",
       "<p>made on a futures and options exchange.\n",
       "Clearing member Not all members of a futures and options exchange are clearing members.\n",
       "</p>\n",
       "<p>All trades must eventually be settled through a clearing member which deals directly with\n",
       "the clearing house.\n",
       "</p>\n",
       "<p>Cliquet (ratchet) option The strike is reset on specific dates according to the spot price of\n",
       "the underlying, locking in interim gains.\n",
       "</p>\n",
       "<p>Collared floating rate note Has a minimum and a maximum coupon rate.\n",
       "Collateral Cash or securities pledged against the performance of some obligation.\n",
       "Collateralized debt obligations (CDOs) Debt securities based on the cash flows from a\n",
       "</p>\n",
       "<p>portfolio of bonds or loans. The securities are normally sold in tranches with different\n",
       "risk/return characteristics.\n",
       "</p>\n",
       "<p>Collateralized mortgage obligations (CMOs) Debt securities based on the cash flows from\n",
       "a pool of mortgage loans.\n",
       "</p>\n",
       "<p>Combination A strategy involving a mixture of options on the same underlying.\n",
       "Commercial bank A bank that makes loans to corporations or governments.\n",
       "Commission The fee charged by a broker to a customer for completing a purchase or sale.\n",
       "Commodity A physical item such as oil, gold or grain. Commodities are traded for spot and\n",
       "</p>\n",
       "<p>for future delivery.\n",
       "Commodity swap At least one of the payment legs depends on the price of a commodity.\n",
       "Common stock US expression for an ordinary share or equity.\n",
       "Compound option An option to buy or sell an option.\n",
       "Continuously compounded rate A method of quoting interest rates commonly used in the\n",
       "</p>\n",
       "<p>derivatives market.</p>\n",
       "<p></p>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "glossary_page_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Call feature\nA feature that allows the issuer of a bond to redeem the bond before maturity. Call option The right but not the obligation to buy an underlying asset at a fixed strike price. Caplet One component of an interest rate cap. Capped floating rate note The rate of interest on the note cannot exceed a given\nChicago Mercantile Exchange The\nChicago futures and options exchange where the key Eurodollar futures contract trades. Also known as the 'Merc'.\nChooser option\nThe holder can decide at a preset time whether it is a call or a put option. Also known as a U-Choose, as-you-like, call-or-put option.\nClean price\nThe price of a bond excluding interest accrued since the last coupon date. Clearing house The organization that registers, matches, monitors and guarantees trades\n\nAll trades must eventually be settled through a clearing member which deals directly with the clearing house.\nCliquet option\nThe strike is reset on specific dates according to the spot price of the underlying, locking in interim gains.\nCollared floating rate note\nHas a minimum and a maximum coupon rate. Collateral Cash or securities pledged against the performance of some obligation. Collateralized debt obligations Debt securities based on the cash flows from a\nCollateralized mortgage obligations\nDebt securities based on the cash flows from a pool of mortgage loans.\nCombination\nA strategy involving a mixture of options on the same underlying. Commercial bank A bank that makes loans to corporations or governments. Commission The fee charged by a broker to a customer for completing a purchase or sale. Commodity A physical item such as oil, gold or grain. Commodities are traded for spot and\n"
     ]
    }
   ],
   "source": [
    "for p in glossary_page_1.findAll(name='p'):\n",
    "    # print(p.text)\n",
    "    text = p.text\n",
    "    text = text.replace('’', \"'\")\n",
    "    text = text.replace('‘', \"'\")\n",
    "\n",
    "    # remove Page number \"351\", \"352\" ... \n",
    "    if '.' not in text:\n",
    "        continue\n",
    "\n",
    "    ## remove page number\n",
    "    if re.search(r'Page \\d{3}', text): \n",
    "        continue\n",
    "\n",
    "    ## remove Glossary \n",
    "    if re.search(r'Glossary', text): \n",
    "        continue\n",
    "\n",
    "    ## remove Adapted from Appendix E\n",
    "    # if re.search(r'Adapted from Appendix E', text): \n",
    "    #     continue\n",
    "\n",
    "    ## pass is the first letter is not capital letter\n",
    "    if not re.search(r'^[A-Z]', text):\n",
    "        continue\n",
    "\n",
    "    text = text.replace('\\n', ' ').strip()\n",
    "\n",
    "    # make a text copy and remove all content in bracket\n",
    "    text_copy = text\n",
    "    match = re.search(' \\(.+\\)', text_copy)\n",
    "    if match:\n",
    "        # if found, then remove all content in bracket\n",
    "        start, end = match.span()\n",
    "        text_copy = text_copy[: start] + text_copy[end: ]\n",
    "\n",
    "    # find key phrases inside text copy\n",
    "    text_copy_token = text_copy.split()\n",
    "    key_phrase = ''\n",
    "    \n",
    "    if re.search('^[A-Z]', text_copy_token[1]):\n",
    "        # if the second word start with capital case letter\n",
    "        # find the first word start with lower case letter\n",
    "        for index, word in enumerate(text_copy_token):\n",
    "            if re.search('^[a-z]', word):\n",
    "                key_phrase = ' '.join(text_copy_token[: index-1])\n",
    "                break\n",
    "    else:\n",
    "        # if the second word start with lower case letter\n",
    "        # find the next captial letter\n",
    "        for index, word in enumerate(text_copy_token):\n",
    "            if index == 0:\n",
    "                continue\n",
    "            if re.search('^[A-Z]', word):\n",
    "                key_phrase = ' '.join(text_copy_token[: index])\n",
    "                break\n",
    "\n",
    "    \n",
    "    explanation = text_copy[len(key_phrase):].strip()\n",
    "    # print(explanation)\n",
    "    match = re.search('^\\(.+\\)', explanation)\n",
    "    if match:\n",
    "        end = match.span()[1]\n",
    "        explanation = explanation[end:].strip()\n",
    "\n",
    "      \n",
    "    if text_copy:\n",
    "        print(key_phrase)\n",
    "        print(explanation)\n",
    "        # print(text_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT = []\n",
    "PHRASES = []\n",
    "EXPLANATION = []\n",
    "\n",
    "for page in glossary_pages:\n",
    "        for p in page.findAll(name='p'):\n",
    "            text = p.text\n",
    "            text = text.replace('’', \"'\")\n",
    "            text = text.replace('‘', \"'\")\n",
    "            text = text.replace('–', '-')\n",
    "\n",
    "            # remove Page number \"351\", \"352\" ... \n",
    "            if '.' not in text:\n",
    "                continue\n",
    "\n",
    "            ## remove page number\n",
    "            if re.search(r'Page \\d{3}', text): \n",
    "                continue\n",
    "\n",
    "            ## remove Glossary \n",
    "            if re.search(r'Glossary', text): \n",
    "                continue\n",
    "\n",
    "            ## remove Adapted from Appendix E\n",
    "            # if re.search(r'Adapted from Appendix E', text): \n",
    "            #     continue\n",
    "\n",
    "            ## pass is the first letter is not capital letter\n",
    "            if not re.search(r'^[A-Z]', text):\n",
    "                continue\n",
    "\n",
    "            text = text.replace('\\n', ' ').strip()\n",
    "            text_original = text\n",
    "\n",
    "            # make a text copy and remove all content in bracket\n",
    "            text_copy = text\n",
    "            match = re.search(' \\(.+\\)', text_copy)\n",
    "            if match:\n",
    "                # if found, then remove all content in bracket\n",
    "                start, end = match.span()\n",
    "                text_copy = text_copy[: start] + text_copy[end: ]\n",
    "\n",
    "            # find key phrases inside text copy\n",
    "            text_copy_token = text_copy.split()\n",
    "            key_phrase = ''\n",
    "            \n",
    "            if re.search('^[A-Z]', text_copy_token[1]):\n",
    "                # if the second word start with capital case letter\n",
    "                # find the first word start with lower case letter\n",
    "                for index, word in enumerate(text_copy_token):\n",
    "                    if re.search('^[a-z]', word):\n",
    "                        key_phrase = ' '.join(text_copy_token[: index-1])\n",
    "                        break\n",
    "            else:\n",
    "                # if the second word start with lower case letter\n",
    "                # find the next captial letter\n",
    "                for index, word in enumerate(text_copy_token):\n",
    "                    if index == 0:\n",
    "                        continue\n",
    "                    if re.search('^[A-Z]', word):\n",
    "                        key_phrase = ' '.join(text_copy_token[: index])\n",
    "                        break\n",
    "\n",
    "            \n",
    "            explanation = text_copy[len(key_phrase):].strip()\n",
    "            # print(explanation)\n",
    "            match = re.search('^\\(.+\\)', explanation)\n",
    "            if match:\n",
    "                end = match.span()[1]\n",
    "                explanation = explanation[end:].strip()\n",
    "            \n",
    "            if text_copy and key_phrase:\n",
    "                # print(text)\n",
    "                TEXT.append(text_original)\n",
    "                PHRASES.append(key_phrase)\n",
    "                EXPLANATION.append(explanation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "df = pd.DataFrame({'ID': [i for i in range(len(PHRASES))],\n",
    "            'original_glossary_extracted': TEXT,\n",
    "            'key_phrase': PHRASES,\n",
    "            'source_book': ['Derivatives Demystified-A Step-by-Step Guide to Forwards, Futures, Swaps _ Options-sAyYiEd' for _ in range(len(PHRASES))],\n",
    "            'definition_or_explanation': EXPLANATION})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   ID                        original_glossary_extracted  \\\n",
       "0   0  Accreting swap A swap in which the principal i...   \n",
       "1   1  Arbitrageur Someone who takes advantage of arb...   \n",
       "2   2  Asset-or-nothing option An option that pays ou...   \n",
       "3   3  Assignment Formal notification from an exchang...   \n",
       "4   4  As-you-like option See: Chooser option. At-bes...   \n",
       "\n",
       "                key_phrase                                        source_book  \\\n",
       "0           Accreting swap  Derivatives Demystified-A Step-by-Step Guide t...   \n",
       "1              Arbitrageur  Derivatives Demystified-A Step-by-Step Guide t...   \n",
       "2  Asset-or-nothing option  Derivatives Demystified-A Step-by-Step Guide t...   \n",
       "3               Assignment  Derivatives Demystified-A Step-by-Step Guide t...   \n",
       "4       As-you-like option  Derivatives Demystified-A Step-by-Step Guide t...   \n",
       "\n",
       "                           definition_or_explanation  \n",
       "0  A swap in which the principal increases in eac...  \n",
       "1  Someone who takes advantage of arbitrage oppor...  \n",
       "2  An option that pays out an amount equal to the...  \n",
       "3  Formal notification from an exchange that the ...  \n",
       "4  See: Chooser option. At-best order An order to...  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>original_glossary_extracted</th>\n      <th>key_phrase</th>\n      <th>source_book</th>\n      <th>definition_or_explanation</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>Accreting swap A swap in which the principal i...</td>\n      <td>Accreting swap</td>\n      <td>Derivatives Demystified-A Step-by-Step Guide t...</td>\n      <td>A swap in which the principal increases in eac...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>Arbitrageur Someone who takes advantage of arb...</td>\n      <td>Arbitrageur</td>\n      <td>Derivatives Demystified-A Step-by-Step Guide t...</td>\n      <td>Someone who takes advantage of arbitrage oppor...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>Asset-or-nothing option An option that pays ou...</td>\n      <td>Asset-or-nothing option</td>\n      <td>Derivatives Demystified-A Step-by-Step Guide t...</td>\n      <td>An option that pays out an amount equal to the...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>Assignment Formal notification from an exchang...</td>\n      <td>Assignment</td>\n      <td>Derivatives Demystified-A Step-by-Step Guide t...</td>\n      <td>Formal notification from an exchange that the ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>As-you-like option See: Chooser option. At-bes...</td>\n      <td>As-you-like option</td>\n      <td>Derivatives Demystified-A Step-by-Step Guide t...</td>\n      <td>See: Chooser option. At-best order An order to...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "source": [
    "## Reformat extraction"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def find_full_expression_and_abbreviation(text):\n",
    "    text_length = len(text)\n",
    "    match = re.search('\\(.+\\)', text) # search of bracket\n",
    "    match_1 = re.search('[A-Z]{2,8}', text) # search for Capitalization\n",
    "    match_2 = re.search('[A-Z]/[A-Z]', text) # search for Capitalization\n",
    "    if match and (match_1 or match_2):\n",
    "        content_in_bracket_length = len(match.group(0)) - 2\n",
    "    else:\n",
    "        if re.search('\\(.+', text):\n",
    "            pos = re.search('\\(.+', text).span()[0]\n",
    "            return [text[:pos-1]]\n",
    "\n",
    "        else:\n",
    "            return [text]\n",
    "\n",
    "    start, end = re.search('\\(.+\\)', text).span()\n",
    "    if content_in_bracket_length > text_length / 2:\n",
    "        \n",
    "        full_expression = text[start+1: end-1]\n",
    "        abbreviated_expression = text[: start-1]\n",
    "    else:\n",
    "        full_expression = text[: start-1]\n",
    "        abbreviated_expression = text[start+1: end-1]\n",
    "\n",
    "    return [full_expression, abbreviated_expression]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "full = []\n",
    "extracted_acronym_1 = []\n",
    "extracted_acronym_2 = []\n",
    "\n",
    "for phrase, definition  in zip(df['key_phrase'].values, df['definition_or_explanation'].values):\n",
    "     res = find_full_expression_and_abbreviation(phrase)\n",
    "     if len(res) == 1:\n",
    "         full.append(res[0])\n",
    "         extracted_acronym_1.append('')\n",
    "         extracted_acronym_2.append('')\n",
    "\n",
    "     if len(res) == 2:\n",
    "         full.append(res[0])\n",
    "         extracted_acronym_1.append(res[1])\n",
    "         extracted_acronym_2.append('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['key_phrase'] = full\n",
    "df['extracted_acronym_1'] = extracted_acronym_1\n",
    "df['extracted_acronym_2'] = extracted_acronym_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_extracted_key_phrase(phrase):\n",
    "    phrase = phrase.replace('-', ' ')\n",
    "    phrase = phrase.replace('/', ' ')\n",
    "    return phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['key_phrase'] = df['key_phrase'].apply(clean_extracted_key_phrase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Index(['ID', 'original_glossary_extracted', 'key_phrase', 'source_book',\n",
       "       'definition_or_explanation', 'extracted_acronym_1',\n",
       "       'extracted_acronym_2'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['ID', 'original_glossary_extracted', 'key_phrase', 'extracted_acronym_1',\n",
    "       'extracted_acronym_2', 'definition_or_explanation', 'source_book',\n",
    "        ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('glossary_extraction_Derivatives Demystified-A Step-by-Step Guide to Forwards, Futures, Swaps _ Options-sAyYiEd.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}